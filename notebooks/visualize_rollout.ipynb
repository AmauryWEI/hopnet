{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOPNet Autoregressive Rollout Visualization\n",
    "\n",
    "This notebook can be used to visualize in 3D the autoregressive rollout output of a \n",
    "pre-trained model on a single dataset sample.\n",
    "\n",
    "Modify the [1. Sample & Model Configuration](#1-sample--model-configuration) code cell\n",
    "to adjust the model and the dataset sample you want to process.\n",
    "\n",
    "## 0. Notebook Configuration\n",
    "\n",
    "This section should not be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Packages import\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from os import path as opath\n",
    "from sys import path as spath\n",
    "\n",
    "spath.append(opath.join(opath.abspath(''), \"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import trimesh\n",
    "\n",
    "from data.movi_dataset import MoviNormalization\n",
    "from scripts.main import get_meshes, get_model, quat_multiply\n",
    "from utils.complexes import compute_nodes_and_objects_positions\n",
    "from utils.plots import plot_errors\n",
    "from utils.rollout import (\n",
    "    build_base_complex,\n",
    "    build_featured_complex,\n",
    "    compute_nodes_positions,\n",
    "    model_input_from_ccc,\n",
    "    positions_from_model_output,\n",
    "    shape_matching,\n",
    ")\n",
    "\n",
    "# General Configuration (do not change)\n",
    "H: int = 2  # Horizon\n",
    "MESHES_LOCATION: str = \"../data/objects/\"\n",
    "MESH_FILENAME: str = \"collision_geometry.obj\"\n",
    "METADATA_FILENAME: str = \"metadata.json\"\n",
    "COLOR_PALETTE = px.colors.qualitative.Plotly\n",
    "\n",
    "FLOOR_FRICTION: float = 0.30  # Constant from Kubric\n",
    "FLOOR_RESTITUTION: float = 0.50  # Constant from Kubric\n",
    "FLOOR_SIZE: float = 20.0  # Minimal approximation, Kubric uses 40\n",
    "FLOOR = trimesh.Trimesh(\n",
    "    vertices=[\n",
    "        [-FLOOR_SIZE, -FLOOR_SIZE, 0],\n",
    "        [-FLOOR_SIZE, FLOOR_SIZE, 0],\n",
    "        [FLOOR_SIZE, -FLOOR_SIZE, 0],\n",
    "        [FLOOR_SIZE, FLOOR_SIZE, 0],\n",
    "    ],\n",
    "    faces=[[0, 1, 2], [1, 2, 3]],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sample & Model Configuration\n",
    "\n",
    "First, choose the model checkpoint that you want to test. Make sure that you select the\n",
    "right normalization file (*i.e.* the one with which the model was trained).\n",
    "\n",
    "Then, choose the dataset sample you want to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL CONFIGURATION\n",
    "MODEL_NAME: str = \"HOPNet\"\n",
    "MODEL_CHECKPOINT_FILE: str = \"../checkpoints/models_seed0_e39.pt\"\n",
    "NORMALIZATION_FILE: str = \"../samples/normalization-movis.npy\"\n",
    "COLLISION_RADIUS: float = 0.1 # Default = 0.1\n",
    "NUM_CHANNELS: int = 128 # Default = 128\n",
    "NUM_LAYERS: int = 1 # Default = 1\n",
    "MLP_LAYERS: int = 2 # Default = 2\n",
    "\n",
    "# DATASET SAMPLE CONFIGURATION\n",
    "SAMPLE_PATH: str = \"../samples/MoVi-B/1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the configuration (do not change)\n",
    "assert MODEL_NAME in [\"HOPNet\", \"NoObjectCells\", \"NoSequential\"]\n",
    "assert NUM_CHANNELS > 0\n",
    "assert NUM_LAYERS > 0\n",
    "assert MLP_LAYERS > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Sample Data\n",
    "\n",
    "This section loads the sample data using the specified location in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metadata\n",
    "metadata_path: str = opath.join(SAMPLE_PATH, METADATA_FILENAME)\n",
    "with open(metadata_path) as f:\n",
    "    metadata: dict = json.load(f)\n",
    "\n",
    "# Extract key information about the sample\n",
    "num_frames: int = metadata[\"metadata\"][\"num_frames\"]\n",
    "num_objects: int = metadata[\"metadata\"][\"num_instances\"]\n",
    "step_rate_hz: int = metadata[\"metadata\"][\"step_rate\"]\n",
    "objects: list[dict] = metadata[\"instances\"]\n",
    "\n",
    "# Create the virtual scene representing the sample\n",
    "meshes = get_meshes(objects)\n",
    "\n",
    "# Add floor data (not present by default in the sample metadata)\n",
    "floor_metadata = {\n",
    "    \"asset_id\": \"floor\",\n",
    "    \"angular_velocities\": np.zeros((num_frames, 3)).tolist(),\n",
    "    \"friction\": FLOOR_FRICTION,\n",
    "    \"mass\": 0.0,\n",
    "    \"positions\": np.zeros((num_frames, 3)).tolist(),\n",
    "    \"quaternions\": np.repeat([[1.0, 0.0, 0.0, 0.0]], num_frames, axis=0).tolist(),\n",
    "    \"restitution\": FLOOR_RESTITUTION,\n",
    "    \"size\": 1.0,\n",
    "    \"velocities\": np.zeros((num_frames, 3)).tolist(),\n",
    "}\n",
    "objects.append(floor_metadata)\n",
    "meshes.append(FLOOR)\n",
    "\n",
    "assert len(objects) == len(meshes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the Model\n",
    "\n",
    "This section loads the model using the specified location provided in \n",
    "[1. Sample & Model Configuration](#1-sample--model-configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the normalization used for model training\n",
    "normalization = MoviNormalization(NORMALIZATION_FILE)\n",
    "\n",
    "# Load the model checkpoint\n",
    "device = torch.device(\"cpu\")\n",
    "model = get_model(MODEL_NAME, NUM_CHANNELS, NUM_LAYERS, MLP_LAYERS).to(device)\n",
    "weights = torch.load(MODEL_CHECKPOINT_FILE, map_location=device)\n",
    "model.load_state_dict(weights, strict=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute and Visualize the Ground Truth\n",
    "\n",
    "Compute the actual ground truth using the ground truth positions and the ground\n",
    "truth accelerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the target features learned by the network\n",
    "(\n",
    "    nodes_positions,\n",
    "    nodes_target_a,\n",
    "    nodes_feature_v,\n",
    "    objects_positions,\n",
    "    objects_target_a,\n",
    "    objects_feature_v,\n",
    "    complex,\n",
    "    triangles_ids,\n",
    ") = compute_nodes_and_objects_positions(objects, meshes, MODEL_NAME == \"NoObjectCells\")\n",
    "\n",
    "objects_quaternions = np.moveaxis(\n",
    "    np.array([obj[\"quaternions\"] for obj in objects]), 0, 1\n",
    ")\n",
    "\n",
    "# Re-compute the positions if the model was perfect\n",
    "gt_nodes_positions = np.zeros_like(nodes_positions)\n",
    "gt_nodes_positions[1:, :, :] = (\n",
    "    nodes_target_a[1:, :, :]\n",
    "    + 2 * nodes_positions[1:, :, :]\n",
    "    - nodes_positions[0:-1, :, :]\n",
    ")\n",
    "\n",
    "# Re-align with the model output based on the horizon\n",
    "t_start: int = H\n",
    "t_end: int = gt_nodes_positions.shape[0] - 1\n",
    "\n",
    "# At time t, the GT node positions are equal to the node positions at t+1\n",
    "assert np.isclose(\n",
    "    gt_nodes_positions[t_start:t_end, :, :],\n",
    "    nodes_positions[t_start + 1 : t_end + 1, :, :],\n",
    ").all()\n",
    "\n",
    "# Re-compute the positions if the model was perfect\n",
    "gt_objs_positions = np.zeros_like(objects_positions)\n",
    "gt_objs_positions[1:, :, :] = (\n",
    "    objects_target_a[1:, :, :]\n",
    "    + 2 * objects_positions[1:, :, :]\n",
    "    - objects_positions[0:-1, :, :]\n",
    ")\n",
    "\n",
    "# Re-align with the model output based on the horizon\n",
    "t_start: int = H\n",
    "t_end: int = gt_objs_positions.shape[0] - 1\n",
    "\n",
    "# At time t, the GT node positions are equal to the node positions at t+1\n",
    "assert np.isclose(\n",
    "    gt_objs_positions[t_start:t_end, :, :],\n",
    "    objects_positions[t_start + 1 : t_end + 1, :, :],\n",
    ").all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell plots the distribution of the target acceleration for nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of the acceleration\n",
    "fig = make_subplots(\n",
    "    rows=1,\n",
    "    cols=3,\n",
    "    subplot_titles=[\"X-Acceleration\", \"Y-acceleration\", \"Z-acceleration\"],\n",
    "    shared_yaxes=True,\n",
    ")\n",
    "fig.add_histogram(\n",
    "    x=nodes_target_a[t_start:t_end, :, 0].flatten(),\n",
    "    row=1,\n",
    "    col=1,\n",
    "    histnorm=\"percent\",\n",
    "    name=\"X-Acceleration\",\n",
    ")\n",
    "fig.add_histogram(\n",
    "    x=nodes_target_a[t_start:t_end, :, 1].flatten(),\n",
    "    row=1,\n",
    "    col=2,\n",
    "    histnorm=\"percent\",\n",
    "    name=\"Y-acceleration\",\n",
    ")\n",
    "fig.add_histogram(\n",
    "    x=nodes_target_a[t_start:t_end, :, 2].flatten(),\n",
    "    row=1,\n",
    "    col=3,\n",
    "    histnorm=\"percent\",\n",
    "    name=\"Z-acceleration\",\n",
    ")\n",
    "for i in range(1, 4):\n",
    "    fig.update_xaxes(title=r\"Acceleration ms^{-2}\", row=1, col=i)\n",
    "fig.update_yaxes(title_text=r\"Percentage [%]\", row=1, col=1)\n",
    "fig.update_layout(yaxis1_type=\"log\")\n",
    "fig.update_layout(yaxis2_type=\"log\")\n",
    "fig.update_layout(yaxis3_type=\"log\")\n",
    "fig.show()\n",
    "\n",
    "print(\"X-accel mean:\", np.mean(nodes_target_a[t_start:t_end, :, 0]))\n",
    "print(\"X-accel std :\", np.std(nodes_target_a[t_start:t_end, :, 0]))\n",
    "print(\"Y-accel mean:\", np.mean(nodes_target_a[t_start:t_end, :, 1]))\n",
    "print(\"Y-accel std :\", np.std(nodes_target_a[t_start:t_end, :, 1]))\n",
    "print(\"Z-accel mean:\", np.mean(nodes_target_a[t_start:t_end, :, 2]))\n",
    "print(\"Z-accel std :\", np.std(nodes_target_a[t_start:t_end, :, 2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells shows the ground truth of the selected dataset sample. Use the\n",
    "sliding bar at the bottom of the figure to navigate the timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time(time: int, pos: np.ndarray, nodes_and_edges: bool ) -> list[go.Mesh3d]:\n",
    "    data = []\n",
    "    nodes_count: int = 0\n",
    "    for obj_idx, mesh in enumerate(meshes):\n",
    "        tmp_mesh = mesh.copy()\n",
    "        tmp_pos: np.ndarray = np.array(objects[obj_idx][\"positions\"][time])\n",
    "        quat: np.ndarray = np.array(objects[obj_idx][\"quaternions\"][time])\n",
    "        tmp_mesh.apply_transform(trimesh.transformations.quaternion_matrix(quat))\n",
    "        tmp_mesh.apply_translation(tmp_pos)\n",
    "        mesh_nodes = len(tmp_mesh.vertices)\n",
    "        data.append(\n",
    "            go.Mesh3d(\n",
    "                x=pos[time, nodes_count : nodes_count + mesh_nodes, 0],\n",
    "                y=pos[time, nodes_count : nodes_count + mesh_nodes, 1],\n",
    "                z=pos[time, nodes_count : nodes_count + mesh_nodes, 2],\n",
    "                i=mesh.faces[:, 0],\n",
    "                j=mesh.faces[:, 1],\n",
    "                k=mesh.faces[:, 2],\n",
    "                showscale=True,\n",
    "                color=px.colors.qualitative.Plotly[obj_idx] if obj_idx != len(meshes) -1 else \"#1F77B4\"\n",
    "            )\n",
    "        )\n",
    "        nodes_count += mesh_nodes\n",
    "\n",
    "        if nodes_and_edges:\n",
    "            data.append(\n",
    "                go.Scatter3d(\n",
    "                    x=tmp_mesh.vertices[:, 0],\n",
    "                    y=tmp_mesh.vertices[:, 1],\n",
    "                    z=tmp_mesh.vertices[:, 2],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(size=2, color=\"black\"),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Uncomment to mesh triangles edges as lines\n",
    "            for face_idx in range(len(tmp_mesh.triangles)):\n",
    "                data.append(\n",
    "                    go.Scatter3d(\n",
    "                        x=tmp_mesh.triangles[face_idx][[0, 1, 2, 0], 0],\n",
    "                        y=tmp_mesh.triangles[face_idx][[0, 1, 2, 0], 1],\n",
    "                        z=tmp_mesh.triangles[face_idx][[0, 1, 2, 0], 2],\n",
    "                        mode=\"lines\",\n",
    "                        line=dict(color=\"black\", width=2),\n",
    "                    )\n",
    "                )\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_end = 478\n",
    "slider_steps = [\n",
    "    {\n",
    "        \"args\": [\n",
    "            [time],\n",
    "            {\n",
    "                \"frame\": {\"duration\": 1 / 240, \"redraw\": True},\n",
    "                \"mode\": \"immediate\",\n",
    "                \"transition\": {\"duration\": 300},\n",
    "            },\n",
    "        ],\n",
    "        \"label\": time,\n",
    "        \"method\": \"animate\",\n",
    "    }\n",
    "    for time in range(t_start + 1, t_end)\n",
    "]\n",
    "\n",
    "sliders_dict = {\n",
    "    \"active\": 0,\n",
    "    \"yanchor\": \"top\",\n",
    "    \"xanchor\": \"left\",\n",
    "    \"transition\": {\"duration\": t_end - t_start, \"easing\": \"cubic-in-out\"},\n",
    "    \"pad\": {\"b\": 10, \"t\": 50},\n",
    "    \"len\": 0.9,\n",
    "    \"x\": 0.1,\n",
    "    \"y\": 0,\n",
    "    \"steps\": slider_steps,\n",
    "}\n",
    "\n",
    "frames = [\n",
    "    go.Frame(\n",
    "        data=plot_time(t, gt_nodes_positions, \"MoVi-B\" not in SAMPLE_PATH), name=str(t)\n",
    "    )\n",
    "    for t in range(t_start + 1, t_end)\n",
    "]\n",
    "fig = go.Figure(\n",
    "    data=plot_time(t_start, gt_nodes_positions, \"MoVi-B\" not in SAMPLE_PATH),\n",
    "    frames=frames,\n",
    ")\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            nticks=4,\n",
    "            range=[-8, 8],\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            nticks=4,\n",
    "            range=[-8, 8],\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            nticks=4,\n",
    "            range=[-8, 8],\n",
    "        ),\n",
    "    ),\n",
    "    height=1200,\n",
    "    margin=dict(r=20, l=10, b=10, t=10),\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            buttons=[\n",
    "                {\n",
    "                    \"args\": [\n",
    "                        None,\n",
    "                        {\n",
    "                            \"frame\": {\"duration\": 0, \"redraw\": True},\n",
    "                            \"fromcurrent\": True,\n",
    "                        },\n",
    "                    ],\n",
    "                    \"label\": \"Play\",\n",
    "                    \"method\": \"animate\",\n",
    "                },\n",
    "                {\n",
    "                    \"args\": [\n",
    "                        [None],\n",
    "                        {\n",
    "                            \"frame\": {\"duration\": 0, \"redraw\": False},\n",
    "                            \"mode\": \"immediate\",\n",
    "                            \"transition\": {\"duration\": 0},\n",
    "                        },\n",
    "                    ],\n",
    "                    \"label\": \"Pause\",\n",
    "                    \"method\": \"animate\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    "    sliders=[sliders_dict],\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compute Autoregressive Rollout\n",
    "\n",
    "This section computes the auto-regressive rollout on the selected sample using the\n",
    "selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoregressive rollout configuration\n",
    "START_TIME: int = 100\n",
    "ROLLOUT_DURATION: int = 100\n",
    "\n",
    "assert START_TIME > 0\n",
    "assert ROLLOUT_DURATION > 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Compute the first nodes and objects positions for horizon H\n",
    "objects_init = deepcopy(objects)\n",
    "base_ccc, triangle_ids, obj_idx_from_node_idx = build_base_complex(\n",
    "    meshes, objects, MODEL_NAME == \"NoObjectCells\"\n",
    ")\n",
    "\n",
    "# Keep only the first H+1 timesteps\n",
    "for obj in objects_init:\n",
    "    obj[\"positions\"] = np.array(obj[\"positions\"]).tolist()\n",
    "    obj[\"quaternions\"] = np.array(obj[\"quaternions\"]).tolist()\n",
    "\n",
    "# Initial object positions\n",
    "obj_pos = np.array(\n",
    "    [\n",
    "        np.array(obj[\"positions\"])[START_TIME : START_TIME + H + 2]\n",
    "        for obj in objects_init\n",
    "    ]\n",
    ")\n",
    "obj_pos = np.moveaxis(obj_pos, 0, 1)  # Shape [timesteps, obj_count, 3]\n",
    "obj_quat = np.array(\n",
    "    [\n",
    "        np.array(obj[\"quaternions\"])[START_TIME : START_TIME + H + 2]\n",
    "        for obj in objects_init\n",
    "    ]\n",
    ")\n",
    "obj_quat = np.moveaxis(obj_quat, 0, 1)  # Shape [timesteps, obj_count, 4]\n",
    "\n",
    "# Ground truth from metadata.json\n",
    "objects_quaternions = np.array([o[\"quaternions\"] for o in objects])\n",
    "objects_quaternions = np.swapaxes(objects_quaternions, 0, 1)\n",
    "\n",
    "# Run the rollout for a certain number of timesteps\n",
    "for t in tqdm(range(H + 1, H + 1 + ROLLOUT_DURATION)):\n",
    "    # Step 1: Create the CCC\n",
    "    ccc, nodes_pos, _ = build_featured_complex(\n",
    "        base_ccc,\n",
    "        None,\n",
    "        triangle_ids,\n",
    "        obj_idx_from_node_idx,\n",
    "        obj_pos[t - H : t + 1],\n",
    "        obj_quat[t - H : t + 1],\n",
    "        objects,\n",
    "        meshes,\n",
    "        MODEL_NAME == \"NoObjectCells\",\n",
    "        H,\n",
    "        COLLISION_RADIUS,\n",
    "    )\n",
    "\n",
    "    # Step 2: Model inference\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out0, out4 = model(\n",
    "            *model_input_from_ccc(\n",
    "                ccc,\n",
    "                horizon=H,\n",
    "                norm=normalization,\n",
    "                model=model,\n",
    "                model_name=MODEL_NAME,\n",
    "                device=device,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Step 3: Compute predicted positions from accelerations\n",
    "    pred_nodes_pos = positions_from_model_output(\n",
    "        out0, normalization, nodes_pos[-2:]\n",
    "    )\n",
    "\n",
    "    # Step 4: Compute shape matching for the new object rotation\n",
    "    new_obj_pos, new_obj_quat = shape_matching(pred_nodes_pos, meshes)\n",
    "\n",
    "    # Step 5: Update the obj_pos and obj_quat with the predicted positions\n",
    "    obj_pos = np.concatenate((obj_pos, np.expand_dims(new_obj_pos, 0)), axis=0)\n",
    "    obj_quat = np.concatenate((obj_quat, np.expand_dims(new_obj_quat, 0)), axis=0)\n",
    "\n",
    "nodes_pos = np.stack(\n",
    "    [\n",
    "        compute_nodes_positions(meshes, obj_pos[t], obj_quat[t])\n",
    "        for t in range(obj_pos.shape[0])\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize the Autogressive Rollout\n",
    "\n",
    "This section shows the autoregressive rollout. Use the sliding bar at the bottom of the\n",
    "figure to navigate the timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slider_steps = [\n",
    "    {\n",
    "        \"args\": [\n",
    "            [time],\n",
    "            {\n",
    "                \"frame\": {\"duration\": 1 / 240, \"redraw\": True},\n",
    "                \"mode\": \"immediate\",\n",
    "                \"transition\": {\"duration\": 300},\n",
    "            },\n",
    "        ],\n",
    "        \"label\": time,\n",
    "        \"method\": \"animate\",\n",
    "    }\n",
    "    for time in range(0, nodes_pos.shape[0])\n",
    "]\n",
    "\n",
    "sliders_dict = {\n",
    "    \"active\": 0,\n",
    "    \"yanchor\": \"top\",\n",
    "    \"xanchor\": \"left\",\n",
    "    \"transition\": {\"duration\": t_end - t_start, \"easing\": \"cubic-in-out\"},\n",
    "    \"pad\": {\"b\": 10, \"t\": 50},\n",
    "    \"len\": 0.9,\n",
    "    \"x\": 0.1,\n",
    "    \"y\": 0,\n",
    "    \"steps\": slider_steps,\n",
    "}\n",
    "\n",
    "frames3 = [\n",
    "    go.Frame(data=plot_time(t, nodes_pos, \"MoVi-B\" not in SAMPLE_PATH), name=str(t))\n",
    "    for t in range(0, nodes_pos.shape[0])\n",
    "]\n",
    "fig3 = go.Figure(\n",
    "    data=plot_time(0, nodes_pos, \"MoVi-B\" not in SAMPLE_PATH), frames=frames3\n",
    ")\n",
    "fig3.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            nticks=4,\n",
    "            range=[-8, 8],\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            nticks=4,\n",
    "            range=[-8, 8],\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            nticks=4,\n",
    "            range=[-8, 8],\n",
    "        ),\n",
    "    ),\n",
    "    height=1200,\n",
    "    margin=dict(r=20, l=10, b=10, t=10),\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            buttons=[\n",
    "                {\n",
    "                    \"args\": [\n",
    "                        None,\n",
    "                        {\n",
    "                            \"frame\": {\"duration\": 0, \"redraw\": True},\n",
    "                            \"fromcurrent\": True,\n",
    "                        },\n",
    "                    ],\n",
    "                    \"label\": \"Play\",\n",
    "                    \"method\": \"animate\",\n",
    "                },\n",
    "                {\n",
    "                    \"args\": [\n",
    "                        [None],\n",
    "                        {\n",
    "                            \"frame\": {\"duration\": 0, \"redraw\": False},\n",
    "                            \"mode\": \"immediate\",\n",
    "                            \"transition\": {\"duration\": 0},\n",
    "                        },\n",
    "                    ],\n",
    "                    \"label\": \"Pause\",\n",
    "                    \"method\": \"animate\",\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    "    sliders=[sliders_dict],\n",
    ")\n",
    "\n",
    "fig3.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors = np.zeros((1, 1, 5, ROLLOUT_DURATION + H + 2))\n",
    "\n",
    "# Compute position RMSE and MAE\n",
    "pos_err = (\n",
    "    obj_pos - objects_positions[START_TIME : START_TIME + ROLLOUT_DURATION + H + 2]\n",
    ")\n",
    "pos_mae = np.mean(np.linalg.norm(pos_err, axis=-1), axis=-1)\n",
    "pos_rmse = np.sqrt(np.mean(np.linalg.norm(pos_err, axis=-1) ** 2, axis=-1))\n",
    "all_errors[0, 0, 0] = pos_mae\n",
    "all_errors[0, 0, 1] = pos_rmse\n",
    "\n",
    "# Compute orientation RMSE and MAE\n",
    "obj_quat_conj = deepcopy(obj_quat)\n",
    "obj_quat_conj[:, :, 1:4] *= -1\n",
    "ori_err = 2 * np.arcsin(\n",
    "    np.linalg.norm(\n",
    "        quat_multiply(\n",
    "            objects_quaternions[START_TIME : START_TIME + ROLLOUT_DURATION + H + 2],\n",
    "            obj_quat_conj,\n",
    "        )[:, :, 1:],\n",
    "        axis=-1,\n",
    "    )\n",
    ")\n",
    "ori_err *= 360 / (2 * np.pi)\n",
    "ori_rmse = np.sqrt(np.nanmean(ori_err**2, axis=-1))\n",
    "ori_mae = np.nanmean(ori_err, axis=-1)\n",
    "all_errors[0, 0, 2] = ori_mae\n",
    "all_errors[0, 0, 3] = ori_rmse\n",
    "\n",
    "fig = plot_errors(all_errors)\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hopnet_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
